{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESRGAN:\n",
    "    \"\"\"\n",
    "    Implementation of ESRGAN following the paper:\n",
    "    'ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks'\n",
    "    For grayscale medical images.\n",
    "    \"\"\"\n",
    "    def __init__(self, scale_factor=4):\n",
    "        self.scale_factor = scale_factor\n",
    "        self.generator = None\n",
    "        self.discriminator = None\n",
    "        self.vgg = None\n",
    "        self.build_models()\n",
    "        \n",
    "    def _residual_dense_block(self, x, features=64):\n",
    "        \"\"\"Residual Dense Block\"\"\"\n",
    "        concat_features = []\n",
    "        input_features = x\n",
    "        \n",
    "        for i in range(5):\n",
    "            if concat_features:\n",
    "                x = layers.Concatenate()(concat_features + [x])\n",
    "            x = layers.Conv2D(features, (3, 3), padding='same')(x)\n",
    "            x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "            concat_features.append(x)\n",
    "            \n",
    "        x = layers.Concatenate()(concat_features)\n",
    "        x = layers.Conv2D(features, (1, 1), padding='same')(x)\n",
    "        \n",
    "        # Local residual learning\n",
    "        return layers.Add()([input_features, x * 0.2])\n",
    "    \n",
    "    def _rrdb_block(self, x, features=64):\n",
    "        \"\"\"Residual in Residual Dense Block\"\"\"\n",
    "        input_features = x\n",
    "        \n",
    "        for _ in range(3):\n",
    "            x = self._residual_dense_block(x, features)\n",
    "            \n",
    "        # Residual scaling\n",
    "        return layers.Add()([input_features, x * 0.2])\n",
    "    \n",
    "    def build_models(self):\n",
    "        # Generator (Modified for Grayscale)\n",
    "        lr_input = Input(shape=(None, None, 1))  # Grayscale input (single channel)\n",
    "        \n",
    "        # First conv\n",
    "        x = layers.Conv2D(64, (3, 3), padding='same')(lr_input)\n",
    "        initial_feature = x\n",
    "        \n",
    "        # RRDB blocks (23 blocks as in paper)\n",
    "        for _ in range(23):\n",
    "            x = self._rrdb_block(x)\n",
    "            \n",
    "        # Global feature fusion\n",
    "        x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "        trunk = layers.Add()([initial_feature, x])\n",
    "        \n",
    "        # Upsampling blocks (4x)\n",
    "        for _ in range(2):  # Two blocks for 4x upsampling\n",
    "            x = layers.Conv2D(256, (3, 3), padding='same')(trunk)\n",
    "            x = tf.nn.depth_to_space(x, 2)  # Pixel shuffle\n",
    "            x = layers.LeakyReLU(0.2)(x)\n",
    "            trunk = x\n",
    "        \n",
    "        # Final conv\n",
    "        sr_output = layers.Conv2D(1, (3, 3), padding='same', activation='tanh')(trunk)  # Single channel output\n",
    "        \n",
    "        self.generator = Model(lr_input, sr_output, name='generator')\n",
    "        \n",
    "        # Discriminator (Modified for Grayscale)\n",
    "        def d_block(x, filters, strides=1, bn=True):\n",
    "            x = layers.Conv2D(filters, (3, 3), strides=strides, padding='same')(x)\n",
    "            if bn:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            return layers.LeakyReLU(alpha=0.2)(x)\n",
    "        \n",
    "        d_input = Input(shape=(None, None, 1))  # Grayscale input\n",
    "        \n",
    "        # Series of Conv + LeakyReLU + BN\n",
    "        features = [64, 64, 128, 128, 256, 256, 512, 512]\n",
    "        x = d_input\n",
    "        \n",
    "        for idx, f in enumerate(features):\n",
    "            x = d_block(x, f, strides=2 if idx % 2 == 1 else 1)\n",
    "        \n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(1024)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        self.discriminator = Model(d_input, x, name='discriminator')\n",
    "        \n",
    "        # VGG feature extractor for perceptual loss\n",
    "        vgg = VGG19(include_top=False, weights='imagenet', input_shape=(None, None, 3))  # VGG expects 3 channels, but we'll use grayscale\n",
    "        self.vgg = Model(inputs=vgg.input,\n",
    "                        outputs=vgg.get_layer('block5_conv4').output,\n",
    "                        name='vgg')\n",
    "        self.vgg.trainable = False\n",
    "        \n",
    "    def compile(self, \n",
    "                gen_lr=1e-4, \n",
    "                disc_lr=1e-4,\n",
    "                content_weight=1.0,\n",
    "                perceptual_weight=1.0,\n",
    "                adversarial_weight=0.1):\n",
    "        \n",
    "        self.gen_optimizer = tf.keras.optimizers.Adam(gen_lr, beta_1=0.9, beta_2=0.99)\n",
    "        self.disc_optimizer = tf.keras.optimizers.Adam(disc_lr, beta_1=0.9, beta_2=0.99)\n",
    "        \n",
    "        self.content_weight = content_weight\n",
    "        self.perceptual_weight = perceptual_weight\n",
    "        self.adversarial_weight = adversarial_weight\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, lr_images, hr_images):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # Generate fake images\n",
    "            sr_images = self.generator(lr_images, training=True)\n",
    "            \n",
    "            # Discriminator outputs\n",
    "            real_output = self.discriminator(hr_images, training=True)\n",
    "            fake_output = self.discriminator(sr_images, training=True)\n",
    "            \n",
    "            # Content loss (L1 loss as per paper)\n",
    "            content_loss = tf.reduce_mean(tf.abs(hr_images - sr_images))\n",
    "            \n",
    "            # Extract features using VGG (for perceptual loss)\n",
    "            hr_images_rgb = tf.repeat(hr_images, repeats=3, axis=-1)\n",
    "            sr_images_rgb = tf.repeat(sr_images, repeats=3, axis=-1)\n",
    "\n",
    "            hr_features = self.vgg(hr_images_rgb)\n",
    "            sr_features = self.vgg(sr_images_rgb)\n",
    "\n",
    "            perceptual_loss = tf.reduce_mean(tf.abs(hr_features - sr_features))\n",
    "            \n",
    "            # Relativistic average GAN loss\n",
    "            real_logits = real_output - tf.reduce_mean(fake_output)\n",
    "            fake_logits = fake_output - tf.reduce_mean(real_output)\n",
    "            \n",
    "            disc_loss = tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    labels=tf.ones_like(real_logits), logits=real_logits\n",
    "                ) +\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    labels=tf.zeros_like(fake_logits), logits=fake_logits\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            gen_loss = tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    labels=tf.ones_like(fake_logits), logits=fake_logits\n",
    "                ) +\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    labels=tf.zeros_like(real_logits), logits=real_logits\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Total generator loss\n",
    "            total_gen_loss = (\n",
    "                self.content_weight * content_loss +\n",
    "                self.perceptual_weight * perceptual_loss +\n",
    "                self.adversarial_weight * gen_loss\n",
    "            )\n",
    "            \n",
    "        # Compute gradients\n",
    "        gen_gradients = gen_tape.gradient(\n",
    "            total_gen_loss, self.generator.trainable_variables\n",
    "        )\n",
    "        disc_gradients = disc_tape.gradient(\n",
    "            disc_loss, self.discriminator.trainable_variables\n",
    "        )\n",
    "        \n",
    "        # Apply gradients\n",
    "        self.gen_optimizer.apply_gradients(\n",
    "            zip(gen_gradients, self.generator.trainable_variables)\n",
    "        )\n",
    "        self.disc_optimizer.apply_gradients(\n",
    "            zip(disc_gradients, self.discriminator.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'content_loss': content_loss,\n",
    "            'perceptual_loss': perceptual_loss,\n",
    "            'gen_loss': gen_loss,\n",
    "            'disc_loss': disc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\study\\4th year sbme\\1st Term\\Deep Learning\\GANs-Super-Resolution\\.venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, image_dir, batch_size=16, hr_size=128, scale_factor=4):\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.hr_size = hr_size\n",
    "        self.lr_size = hr_size // scale_factor\n",
    "        self.scale_factor = scale_factor\n",
    "        \n",
    "        self.dataset = self._create_dataset()\n",
    "    \n",
    "    def _load_and_process(self, path):\n",
    "        # Load image\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_png(img, channels=1)  # Read as grayscale\n",
    "        img = tf.cast(img, tf.float32) / 127.5 - 1  # Normalize to [-1, 1]\n",
    "        \n",
    "        # Random crop\n",
    "        img = tf.image.random_crop(img, [self.hr_size, self.hr_size, 1])\n",
    "        \n",
    "        # Create low-res version\n",
    "        lr_img = tf.image.resize(img, [self.lr_size, self.lr_size],\n",
    "                               method='bicubic')\n",
    "        \n",
    "        return lr_img, img\n",
    "    \n",
    "    def _create_dataset(self):\n",
    "        # Get image paths\n",
    "        image_paths = tf.data.Dataset.list_files(str(self.image_dir + '/*'))\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = (image_paths\n",
    "                  .map(self._load_and_process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                  .batch(self.batch_size)\n",
    "                  .prefetch(tf.data.AUTOTUNE))\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "# Initialize model\n",
    "model = ESRGAN(scale_factor=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile with custom loss weights if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    gen_lr=1e-4, \n",
    "    disc_lr=1e-4,\n",
    "    content_weight=1.0, \n",
    "    perceptual_weight=1.0,\n",
    "    adversarial_weight=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(image_dir='Dataset/images', batch_size=16, hr_size=128, scale_factor=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (lr_images, hr_images) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdata_loader\u001b[49m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Perform training step\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     losses \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_step(lr_images, hr_images)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Display batch progress\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 1  # Number of epochs\n",
    "# total_batches = len(data_loader)  # Total number of batches per epoch\n",
    "total_batches = 1 # for demonstration purposes\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    for batch_idx, (lr_images, hr_images) in enumerate(data_loader):\n",
    "        # Perform training step\n",
    "        losses = model.train_step(lr_images, hr_images)\n",
    "\n",
    "        # Display batch progress\n",
    "        print(f\"Batch {batch_idx + 1}/{total_batches} - \"\n",
    "              f\"Content Loss: {losses['content_loss']:.4f}, \"\n",
    "              f\"Perceptual Loss: {losses['perceptual_loss']:.4f}, \"\n",
    "              f\"Gen Loss: {losses['gen_loss']:.4f}, \"\n",
    "              f\"Disc Loss: {losses['disc_loss']:.4f}\")\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} completed in {epoch_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses['content_loss'], label='Content Loss')\n",
    "plt.plot(losses['perceptual_loss'], label='Perceptual Loss')\n",
    "plt.plot(losses['gen_loss'], label='Generator Loss')\n",
    "plt.plot(losses['disc_loss'], label='Discriminator Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the generated images and original high-res images and low-res images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(4):\n",
    "    plt.subplot(4, 3, i*3 + 1)\n",
    "    plt.imshow(tf.squeeze(lr_images[i]), cmap='gray')\n",
    "    plt.title('Low-res')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(4, 3, i*3 + 2)\n",
    "    plt.imshow(tf.squeeze(hr_images[i]), cmap='gray')\n",
    "    plt.title('High-res')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    sr_images = model.generator(lr_images, training=False)\n",
    "    plt.subplot(4, 3, i*3 + 3)\n",
    "    plt.imshow(tf.squeeze(sr_images[i]), cmap='gray')\n",
    "    plt.title('Super-res')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
