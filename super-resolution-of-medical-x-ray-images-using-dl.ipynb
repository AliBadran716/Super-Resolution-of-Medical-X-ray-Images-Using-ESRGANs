{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install tensorflow==2.15.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:38.878955Z","iopub.execute_input":"2024-12-31T21:12:38.879310Z","iopub.status.idle":"2024-12-31T21:12:42.237951Z","shell.execute_reply.started":"2024-12-31T21:12:38.879282Z","shell.execute_reply":"2024-12-31T21:12:42.237051Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow==2.15.1 in /usr/local/lib/python3.10/dist-packages (2.15.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.3.2)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.3.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (71.0.4)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (4.12.2)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.64.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (2.15.2)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.44.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.27.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.7)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.1.5)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model, Input\nfrom tensorflow.keras.applications.vgg19 import VGG19\nimport numpy as np\nimport time\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:42.239268Z","iopub.execute_input":"2024-12-31T21:12:42.239557Z","iopub.status.idle":"2024-12-31T21:12:45.345875Z","shell.execute_reply.started":"2024-12-31T21:12:42.239532Z","shell.execute_reply":"2024-12-31T21:12:45.345128Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:45.347238Z","iopub.execute_input":"2024-12-31T21:12:45.347806Z","iopub.status.idle":"2024-12-31T21:12:45.352184Z","shell.execute_reply.started":"2024-12-31T21:12:45.347780Z","shell.execute_reply":"2024-12-31T21:12:45.351365Z"}},"outputs":[{"name":"stdout","text":"2.15.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\n\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\n    \nprint('Found GPU at: {}'.format(device_name))\n\nprint(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:45.353519Z","iopub.execute_input":"2024-12-31T21:12:45.353801Z","iopub.status.idle":"2024-12-31T21:12:45.722539Z","shell.execute_reply.started":"2024-12-31T21:12:45.353778Z","shell.execute_reply":"2024-12-31T21:12:45.721732Z"}},"outputs":[{"name":"stdout","text":"Found GPU at: /device:GPU:0\nGPU available (YESS!!!!)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import gc\ngc.collect()\ntf.keras.backend.clear_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:45.723564Z","iopub.execute_input":"2024-12-31T21:12:45.723875Z","iopub.status.idle":"2024-12-31T21:12:45.900571Z","shell.execute_reply.started":"2024-12-31T21:12:45.723852Z","shell.execute_reply":"2024-12-31T21:12:45.899731Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from tensorflow.keras.mixed_precision import set_global_policy\nset_global_policy('mixed_float16')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:45.901373Z","iopub.execute_input":"2024-12-31T21:12:45.901694Z","iopub.status.idle":"2024-12-31T21:12:45.914031Z","shell.execute_reply.started":"2024-12-31T21:12:45.901662Z","shell.execute_reply":"2024-12-31T21:12:45.913382Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class ESRGAN:\n    \"\"\"\n    Implementation of ESRGAN following the paper:\n    'ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks'\n    For grayscale medical images.\n    \"\"\"\n    def __init__(self, scale_factor=4):\n        self.scale_factor = scale_factor\n        self.generator = None\n        self.discriminator = None\n        self.vgg = None\n        self.build_models()\n        \n    def _residual_dense_block(self, x, features=64):\n        \"\"\"Residual Dense Block\"\"\"\n        concat_features = []\n        input_features = x\n        \n        for i in range(5):\n            if concat_features:\n                x = layers.Concatenate()(concat_features + [x])\n            x = layers.Conv2D(features, (3, 3), padding='same')(x)\n            x = layers.LeakyReLU(alpha=0.2)(x)\n            concat_features.append(x)\n            \n        x = layers.Concatenate()(concat_features)\n        x = layers.Conv2D(features, (1, 1), padding='same')(x)\n        \n        # Local residual learning\n        return layers.Add()([input_features, x * 0.2])\n    \n    def _rrdb_block(self, x, features=64):\n        \"\"\"Residual in Residual Dense Block\"\"\"\n        input_features = x\n        \n        for _ in range(3):\n            x = self._residual_dense_block(x, features)\n            \n        # Residual scaling\n        return layers.Add()([input_features, x * 0.2])\n    \n    def build_models(self):\n        with tf.device('/GPU:0'):\n            # Generator (Modified for Grayscale)\n            lr_input = Input(shape=(None, None, 1))  # Grayscale input (single channel)\n            \n            # First conv\n            x = layers.Conv2D(64, (3, 3), padding='same')(lr_input)\n            initial_feature = x\n            \n            # RRDB blocks (23 blocks as in paper)\n            for _ in range(23):\n                x = self._rrdb_block(x)\n                \n            # Global feature fusion\n            x = layers.Conv2D(64, (3, 3), padding='same')(x)\n            trunk = layers.Add()([initial_feature, x])\n            \n            # Upsampling blocks (4x)\n            for _ in range(2):  # Two blocks for 4x upsampling\n                x = layers.Conv2D(256, (3, 3), padding='same')(trunk)\n                x = tf.nn.depth_to_space(x, 2)  # Pixel shuffle\n                x = layers.LeakyReLU(0.2)(x)\n                trunk = x\n            \n            # Final conv\n            sr_output = layers.Conv2D(1, (3, 3), padding='same', activation='tanh')(trunk)  # Single channel output\n            \n            self.generator = Model(lr_input, sr_output, name='generator')\n            \n            # Discriminator (Modified for Grayscale)\n            def d_block(x, filters, strides=1, bn=True):\n                x = layers.Conv2D(filters, (3, 3), strides=strides, padding='same')(x)\n                if bn:\n                    x = layers.BatchNormalization()(x)\n                return layers.LeakyReLU(alpha=0.2)(x)\n            \n            d_input = Input(shape=(None, None, 1))  # Grayscale input\n            \n            # Series of Conv + LeakyReLU + BN\n            features = [64, 64, 128, 128, 256, 256, 512, 512]\n            x = d_input\n            \n            for idx, f in enumerate(features):\n                x = d_block(x, f, strides=2 if idx % 2 == 1 else 1)\n            \n            x = layers.GlobalAveragePooling2D()(x)\n            x = layers.Dense(1024)(x)\n            x = layers.LeakyReLU(0.2)(x)\n            x = layers.Dense(1, activation='sigmoid')(x)\n            \n            self.discriminator = Model(d_input, x, name='discriminator')\n            \n            # VGG feature extractor for perceptual loss\n            vgg = VGG19(include_top=False, weights='imagenet', input_shape=(None, None, 3))  # VGG expects 3 channels, but we'll use grayscale\n            self.vgg = Model(inputs=vgg.input,\n                            outputs=vgg.get_layer('block5_conv4').output,\n                            name='vgg')\n            self.vgg.trainable = False\n        \n    def compile(self, \n                gen_lr=1e-4, \n                disc_lr=1e-4,\n                content_weight=1.0,\n                perceptual_weight=1.0,\n                adversarial_weight=0.1):\n        \n        self.gen_optimizer = tf.keras.optimizers.Adam(gen_lr, beta_1=0.9, beta_2=0.99)\n        self.disc_optimizer = tf.keras.optimizers.Adam(disc_lr, beta_1=0.9, beta_2=0.99)\n        \n        self.content_weight = content_weight\n        self.perceptual_weight = perceptual_weight\n        self.adversarial_weight = adversarial_weight\n        \n    @tf.function\n    def train_step(self, lr_images, hr_images):\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n            # Generate fake images\n            sr_images = self.generator(lr_images, training=True)\n            \n            # Discriminator outputs\n            real_output = self.discriminator(hr_images, training=True)\n            fake_output = self.discriminator(sr_images, training=True)\n            \n            # Content loss (L1 loss as per paper)\n            content_loss = tf.reduce_mean(tf.abs(tf.cast(hr_images, tf.float16) - sr_images))\n            \n            # Extract features using VGG (for perceptual loss)\n            hr_images_rgb = tf.repeat(hr_images, repeats=3, axis=-1)\n            sr_images_rgb = tf.repeat(sr_images, repeats=3, axis=-1)\n\n            hr_features = self.vgg(hr_images_rgb)\n            sr_features = self.vgg(sr_images_rgb)\n\n            perceptual_loss = tf.reduce_mean(tf.abs(hr_features - sr_features))\n            \n            # Relativistic average GAN loss\n            real_logits = real_output - tf.reduce_mean(fake_output)\n            fake_logits = fake_output - tf.reduce_mean(real_output)\n            \n            disc_loss = tf.reduce_mean(\n                tf.nn.sigmoid_cross_entropy_with_logits(\n                    labels=tf.ones_like(real_logits), logits=real_logits\n                ) +\n                tf.nn.sigmoid_cross_entropy_with_logits(\n                    labels=tf.zeros_like(fake_logits), logits=fake_logits\n                )\n            )\n            \n            gen_loss = tf.reduce_mean(\n                tf.nn.sigmoid_cross_entropy_with_logits(\n                    labels=tf.ones_like(fake_logits), logits=fake_logits\n                ) +\n                tf.nn.sigmoid_cross_entropy_with_logits(\n                    labels=tf.zeros_like(real_logits), logits=real_logits\n                )\n            )\n            \n            # Total generator loss\n            total_gen_loss = (\n                self.content_weight * content_loss +\n                self.perceptual_weight * perceptual_loss +\n                self.adversarial_weight * gen_loss\n            )\n            \n        # Compute gradients\n        gen_gradients = gen_tape.gradient(\n            total_gen_loss, self.generator.trainable_variables\n        )\n        disc_gradients = disc_tape.gradient(\n            disc_loss, self.discriminator.trainable_variables\n        )\n        \n        # Apply gradients\n        self.gen_optimizer.apply_gradients(\n            zip(gen_gradients, self.generator.trainable_variables)\n        )\n        self.disc_optimizer.apply_gradients(\n            zip(disc_gradients, self.discriminator.trainable_variables)\n        )\n        \n        return {\n            'content_loss': content_loss,\n            'perceptual_loss': perceptual_loss,\n            'gen_loss': gen_loss,\n            'disc_loss': disc_loss,\n            'total_gen_loss' : total_gen_loss\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:45.914854Z","iopub.execute_input":"2024-12-31T21:12:45.915061Z","iopub.status.idle":"2024-12-31T21:12:45.934346Z","shell.execute_reply.started":"2024-12-31T21:12:45.915031Z","shell.execute_reply":"2024-12-31T21:12:45.933510Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class DataLoader:\n    def __init__(self, image_dir, batch_size=16, hr_size=1024, scale_factor=4):\n        self.image_dir = image_dir\n        self.batch_size = batch_size\n        self.hr_size = hr_size\n        self.lr_size = hr_size // scale_factor\n        self.scale_factor = scale_factor\n        \n        self.dataset = self._create_dataset()\n    \n    def _load_and_process(self, path):\n        # Load image\n        img = tf.io.read_file(path)\n        img = tf.image.decode_png(img, channels=1)  # Read as grayscale\n        img = tf.cast(img, tf.float32) / 127.5 - 1  # Normalize to [-1, 1]\n        \n        # Random crop\n        img = tf.image.random_crop(img, [self.hr_size, self.hr_size, 1])\n        \n        # Create low-res version\n        lr_img = tf.image.resize(img, [self.lr_size, self.lr_size],\n                               method='bicubic')\n        \n        return lr_img, img\n    \n    def _create_dataset(self):\n        # Get image paths\n        image_paths = tf.data.Dataset.list_files(str(self.image_dir + '/*'))\n        \n        # Create dataset\n        dataset = (image_paths\n                  .map(self._load_and_process, num_parallel_calls=tf.data.AUTOTUNE)\n                  .batch(self.batch_size)\n                  .prefetch(tf.data.AUTOTUNE))\n        \n        return dataset\n    \n# Initialize model\nmodel = ESRGAN(scale_factor=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:45.936628Z","iopub.execute_input":"2024-12-31T21:12:45.936880Z","iopub.status.idle":"2024-12-31T21:12:54.540213Z","shell.execute_reply.started":"2024-12-31T21:12:45.936860Z","shell.execute_reply":"2024-12-31T21:12:54.539502Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Compile with custom loss weights if needed","metadata":{}},{"cell_type":"code","source":"model.compile(\n    gen_lr=1e-4, \n    disc_lr=1e-4,\n    content_weight=1.0, \n    perceptual_weight=1.0,\n    adversarial_weight=1.0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:54.541329Z","iopub.execute_input":"2024-12-31T21:12:54.541582Z","iopub.status.idle":"2024-12-31T21:12:54.550898Z","shell.execute_reply.started":"2024-12-31T21:12:54.541560Z","shell.execute_reply":"2024-12-31T21:12:54.550116Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Load data","metadata":{}},{"cell_type":"code","source":"data_loader = DataLoader(image_dir='/kaggle/input/data/images_007/images', batch_size=2, hr_size=512, scale_factor=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:54.551776Z","iopub.execute_input":"2024-12-31T21:12:54.552107Z","iopub.status.idle":"2024-12-31T21:12:55.958113Z","shell.execute_reply.started":"2024-12-31T21:12:54.552075Z","shell.execute_reply":"2024-12-31T21:12:55.957344Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Training loop","metadata":{}},{"cell_type":"code","source":"tf.debugging.set_log_device_placement(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:55.958864Z","iopub.execute_input":"2024-12-31T21:12:55.959080Z","iopub.status.idle":"2024-12-31T21:12:55.962559Z","shell.execute_reply.started":"2024-12-31T21:12:55.959052Z","shell.execute_reply":"2024-12-31T21:12:55.961724Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Create a history dictionary to store losses over time\nhistory = {\n    'content_loss': [],\n    'perceptual_loss': [],\n    'gen_loss': [],\n    'disc_loss': [],\n    'total_gen_loss': []\n}\n\nepochs = 1\n\n# Training loop\nfor epoch in range(epochs):\n    start_time = time.time()\n    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n\n    accumulation_steps = 4\n    \n    for i, (lr, hr) in enumerate(data_loader.dataset):\n        loss = model.train_step(lr, hr)\n        loss = len(loss['total_gen_loss']) / accumulation_steps\n        loss.backward()\n        \n        if (i + 1) % accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n\n        # Append the current batch losses to the history dictionary\n        history['content_loss'].append(losses['content_loss'].numpy())\n        history['perceptual_loss'].append(losses['perceptual_loss'].numpy())\n        history['gen_loss'].append(losses['gen_loss'].numpy())\n        history['disc_loss'].append(losses['disc_loss'].numpy())\n        history['total_gen_loss'].append(losses['total_gen_loss'].numpy())\n\n        # Print the losses every 100 batches\n        if (batch_idx + 1) % 100 == 0:\n            print(f\"Batch {batch_idx + 1} - \"\n                  f\"Content Loss: {losses['content_loss']:.4f}, \"\n                  f\"Perceptual Loss: {losses['perceptual_loss']:.4f}, \"\n                  f\"Gen Loss: {losses['gen_loss']:.4f}, \"\n                  f\"Disc Loss: {losses['disc_loss']:.4f}, \"\n                  f\"Total Generator Loss: {losses['total_gen_loss']:.4f}\")\n                    \n\n    epoch_time = time.time() - start_time\n    print(f\"Epoch {epoch + 1} completed in {epoch_time:.2f} seconds.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T21:12:55.963388Z","iopub.execute_input":"2024-12-31T21:12:55.963674Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_util.py:504: RuntimeWarning: overflow encountered in cast\n  nparray = values.astype(dtype.as_numpy_dtype)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"Visualize the loss values","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After training, plot the accumulated loss values\nplt.figure(figsize=(10, 6))\nplt.plot(history['content_loss'], label='Content Loss')\nplt.legend()\nplt.xlabel('Batch')\nplt.ylabel('Loss')\nplt.title('Content Losses')\nplt.show()\nplt.plot(history['perceptual_loss'], label='Perceptual Loss')\nplt.legend()\nplt.xlabel('Batch')\nplt.ylabel('Loss')\nplt.title('Perceptual Losses')\nplt.show()\nplt.plot(history['gen_loss'], label='Generator Loss')\nplt.legend()\nplt.xlabel('Batch')\nplt.ylabel('Loss')\nplt.title('Generator Losses')\nplt.show()\nplt.legend()\nplt.plot(history['disc_loss'], label='Discriminator Loss')\nplt.legend()\nplt.xlabel('Batch')\nplt.ylabel('Loss')\nplt.title('Discriminator Losses')\nplt.show()\nplt.plot(history['total_gen_loss'], label='Total Generative Loss')\nplt.legend()\nplt.xlabel('Batch')\nplt.ylabel('Loss')\nplt.title('Total Generative Losses')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Visualize the generated images and original high-res images and low-res images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 15))\nfor i in range(4):\n    plt.subplot(4, 3, i*3 + 1)\n    plt.imshow(tf.squeeze(lr_images[i]), cmap='gray')\n    plt.title('Low-res')\n    plt.axis('off')\n    \n    plt.subplot(4, 3, i*3 + 2)\n    plt.imshow(tf.squeeze(hr_images[i]), cmap='gray')\n    plt.title('High-res')\n    plt.axis('off')\n    \n    sr_images = model.generator(lr_images, training=False)\n    plt.subplot(4, 3, i*3 + 3)\n    plt.imshow(tf.squeeze(sr_images[i]), cmap='gray')\n    plt.title('Super-res')\n    plt.axis('off')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Quantitative Metrics:","metadata":{}},{"cell_type":"markdown","source":"## a) Peak Signal-to-Noise Ratio (PSNR) \n## b) Structural Similarity Index (SSIM) \n## c) Mean Absolute Error (MAE)","metadata":{}},{"cell_type":"code","source":"def psnr(img1, img2):\n    return tf.image.psnr(img1, img2, max_val=1.0)\n\ndef ssim(img1, img2):\n    return tf.image.ssim(img1, img2, max_val=1.0)\n\ndef lpips_score(img1, img2):\n    return lpips_model.forward(img1, img2)\n\ndef mae(img1, img2):\n    return tf.reduce_mean(tf.abs(img1 - img2))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loader = DataLoader(image_dir='/kaggle/input/data/images_008/images', batch_size=2, hr_size=512, scale_factor=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming you have a test dataset and the model is ready\ndef test_model(model, test_loader):\n    psnr_values = []\n    ssim_values = []\n    mae_values = []\n    \n    # Get the total number of batches for progress tracking\n    total_batches = len(test_loader.dataset)\n    \n    # Initialize a progress bar or use simple print for feedback\n    print(\"Testing model...\\n\")\n    \n    for batch_idx, (lr_images, hr_images) in enumerate(test_loader.dataset):\n        # Generate super-resolved images\n        sr_images = model.generator(lr_images, training=False)\n        \n        # Compute metrics\n        psnr_value = psnr(hr_images, sr_images).numpy()\n        ssim_value = ssim(hr_images, sr_images).numpy()\n        mae_value = mae(hr_images, sr_images).numpy()\n\n        # Append the values to lists\n        psnr_values.append(psnr_value)\n        ssim_values.append(ssim_value)\n        mae_values.append(mae_value)\n\n        # Print progress every 100 batches\n        if batch_idx % 100 == 0:\n            print(f\"Batch {batch_idx}/{total_batches} - PSNR: {psnr_value:.4f}, SSIM: {ssim_value:.4f}, MAE: {mae_value:.4f}\")\n    \n    # Compute average values\n    avg_psnr = np.mean(psnr_values)\n    avg_ssim = np.mean(ssim_values)\n    avg_mae = np.mean(mae_values)\n\n    print(f\"\\nTesting completed!\")\n    print(f\"Average PSNR: {avg_psnr:.4f}\")\n    print(f\"Average SSIM: {avg_ssim:.4f}\")\n    print(f\"Average MAE: {avg_mae:.4f}\")\n\n    # Example visualization of results\n    idx = 0  # You can change this to visualize different examples\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 3, 1)\n    plt.imshow(lr_images[idx], cmap='gray')\n    plt.title(\"Low Resolution\")\n    plt.subplot(1, 3, 2)\n    plt.imshow(hr_images[idx], cmap='gray')\n    plt.title(\"Ground Truth\")\n    plt.subplot(1, 3, 3)\n    plt.imshow(sr_images[idx], cmap='gray')\n    plt.title(\"Super-Resolved\")\n    plt.show()\n\n# Run the testing function\ntest_model(model, test_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}